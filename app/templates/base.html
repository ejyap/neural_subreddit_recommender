<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="description" content="Collaborative filtering subreddit recommender built using
    neural networks.">
        <meta name="author" content="Eduardo Yap">
        <title>Subreddit Recommender</title>
        <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">
        <!-- Latest compiled and minified plotly.js JavaScript -->
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

        <!-- OR use a specific plotly.js release (e.g. version 1.5.0) -->
        <script src="https://cdn.plot.ly/plotly-1.5.0.min.js"></script>

        <!-- OR an un-minified version is also available -->
        <script src="https://cdn.plot.ly/plotly-latest.js" charset="utf-8"></script>
    </head>
    <body>
        <nav class="navbar navbar-light bg-light">
            <span class="navbar-brand mb-0 h1">Subreddit Recommender</span>
        </nav>
        <div class="container-fluid">
            <div>
                <form method="post">
                    <label for="input_name">Subreddit: </label>
                    <input name="input_name" value={{ input_name }}>
                    <select name="num_recommendations" id="num_recommendations">
                        <option value="5">5</option>
                        <option value="10">10</option>
                        <option value="15">15</option>
                        <option value="20">20</option>
                    </select>
                    <button type="submit">Recommend</button>
                </form>
            </div>
            {% block content %}{% endblock %}
            {% if plot != "null" %}
            <hr>
            <h2>t-SNE 3D Visualization</h2>
            <div id="3dplot">
                <script>
                    var graph = {{ plot | safe }};
                    if (graph) {
                        Plotly.plot('3dplot', graph.data, graph.layout, {responsive: true});
                    }
                </script>
            </div>
            {% endif %}
            <hr>
            <h2>About</h2>
            <p>Above is a subreddit recommender system I built by using neural network embeddings. I recreated a simplified version of the neural network
                outlined in the paper <a href="https://arxiv.org/pdf/1708.05031.pdf">"Neural Collaborative Filtering"</a>, authored by Xiangnan He in 2017.
                The paper proposes one of the first deep learning architectures modelled for collaborative filtering.
                It managed to outperform many of the popular collaborative filtering methods at the time. Other advances have been done in deep recommender systems since then, but I
                chose this paper, because it was straightforward and easy to apply to my own dataset.
                The dataset consisted of
            Reddit comments from over 30000 users, which I collected myself using the Reddit's PRAW API. After cleaning and preparing, the dataset was comprised of over 1 million user submission across
                54926 unique subreddits. After model training, I ended up with a 40-dimensional embedding vector for each subreddit. Similarity between subreddits is calculated using the
                cosine similarity of their embeddings. Here's a link to the notebook where I trained the neural network. You can find the preprocessed dataset, as well as the embeddings, here.
            </p>
            <p>
                I utilized t-Distributed Stochastic Neighbor Embedding (t-SNE), a dimensionality reduction technique well-suited for high-dimensional data,
                to reduce the dimensionality of the 40 embedding vector to a 3-dimensional space. I then created the 3D Scatter Plot shown above using Plotly to
                visualize the transformed embeddings. The plot updates to show only close neighbors to the current subreddit.
            </p>
            <p>
                While the system does a decent job, there are some limitations. First of all, I only used the hyperparameters suggested by the paper. A better
                performance could be achieved with better hyper parameters, but each training session on the dataset takes about 8 hours. I could've also gotten
                a better performance if I trained it for longer, but the results were already good enough. Another limitation is the size of my dataset. I only
                sampled 30000 users, which leads to a lack of comments from less active subreddits. The neural network has no option but to overfit the few users
                who comment in a particular subreddit, leading to bad recommendations. One final limitation is the model's trainirng time. It took 8 hours
                to train the model on my dataset, but imagine having to training it on millions of users or having to constantly re-train to reflect present user activities.
                It's just too resource consuming. The good thing is that it's not common to have new active subreddits every month. The current popular subreddits will stay
                popular for a long time, so my model will remain relevant as well, even without updates.
            </p>
            <p>
                If you're interested in the code, here's the full project on <a href="https://github.com/ejyap/neural_subreddit_recommender">GitHub</a>.
            </p>
        </div>
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
        <script>
            $("#num_recommendations").val({{ num_recommendations|string }}).change();
        </script>
    </body>
</html>